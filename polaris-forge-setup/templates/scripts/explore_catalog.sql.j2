-- Copyright 2025 Snowflake Inc.
-- SPDX-License-Identifier: Apache-2.0
--
-- Licensed under the Apache License, Version 2.0 (the "License");
-- you may not use this file except in compliance with the License.
-- You may obtain a copy of the License at
--
--     http://www.apache.org/licenses/LICENSE-2.0
--
-- Unless required by applicable law or agreed to in writing, software
-- distributed under the License is distributed on an "AS IS" BASIS,
-- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-- See the License for the specific language governing permissions and
-- limitations under the License.

-- ============================================================================
-- DuckDB Iceberg Extension - Polaris REST Catalog Explorer (SQL Version)
-- ============================================================================
--
-- This script demonstrates using DuckDB's Iceberg extension to interact with
-- Apache Polaris REST Catalog using pure SQL commands.
--
-- This file was auto-generated by Ansible from explore_catalog.sql.j2
-- Generated on: {{ ansible_date_time.iso8601 }}
--
-- Usage:
--   duckdb < scripts/explore_catalog.sql
--   
--   # Or interactively:
--   duckdb
--   .read scripts/explore_catalog.sql
--
-- Reference:
--   https://duckdb.org/docs/stable/core_extensions/iceberg/iceberg_rest_catalogs
--
-- Workflow:
--   1. Load required extensions (iceberg, httpfs)
--   2. Create OAuth2 secret for Polaris authentication
--   3. Attach to Polaris REST Catalog
--   4. Create schema and Iceberg table
--   5. Load CSV data from GitHub
--   6. INSERT data into Iceberg table
--   7. Query and analyze data
--   8. Explore Iceberg metadata and snapshots
--   9. Cleanup (optional)
-- ============================================================================

-- ============================================================================
-- Configuration
-- ============================================================================
-- Catalog: << sql_vars.catalog_name >>
-- Endpoint: << sql_vars.endpoint >>
-- OAuth Server: << sql_vars.oauth_server >>
-- Realm: << sql_vars.realm >>
-- ============================================================================

-- Disable SQL echo to prevent credential exposure in output
.echo off

.print '============================================================================'
.print 'DuckDB Iceberg Extension - Polaris REST Catalog Explorer'
.print '============================================================================'
.print ''

-- ============================================================================
-- Step 1: Setup DuckDB Extensions
-- ============================================================================
.print 'Installing and loading extensions...'

INSTALL iceberg;
LOAD iceberg;

INSTALL httpfs;
LOAD httpfs;

.print 'OK: Extensions loaded successfully'
.print ''

-- ============================================================================
-- Step 2: Load Penguins CSV Data into Memory
-- ============================================================================
.print 'Loading Penguins dataset from GitHub...'

CREATE TEMP TABLE penguins_staging AS 
SELECT * FROM read_csv_auto('https://raw.githubusercontent.com/dataprofessor/data/master/penguins_cleaned.csv');

.print 'OK: Loaded Penguins data into memory'

SELECT COUNT(*) as record_count FROM penguins_staging;

.print ''
.print 'Dataset Schema:'
DESCRIBE penguins_staging;

.print ''

-- ============================================================================
-- Step 3: Connect to Polaris REST Catalog
-- ============================================================================
.print 'Connecting to Polaris REST Catalog...'
.print '    Endpoint: << sql_vars.endpoint >>'
.print '    Catalog:  << sql_vars.catalog_name >>'
.print '    Client:   ****<< sql_vars.client_id[-4:] >>'
.print ''

-- Create OAuth2 secret for Polaris authentication
CREATE OR REPLACE SECRET polaris_secret (
    TYPE iceberg,
    CLIENT_ID '<< sql_vars.client_id >>',
    CLIENT_SECRET '<< sql_vars.client_secret >>',
    OAUTH2_SERVER_URI '<< sql_vars.oauth_server >>'
);

-- Attach to Polaris catalog
ATTACH '<< sql_vars.catalog_name >>' AS polaris_catalog (
    TYPE iceberg,
    SECRET polaris_secret,
    ENDPOINT '<< sql_vars.endpoint >>'
);

.print 'OK: Connected to Polaris catalog (credentials masked)'

-- Verify connection
.print ''
.print 'Existing tables in catalog:'
SHOW ALL TABLES;

.print ''

-- ============================================================================
-- Step 4: Create Schema and Iceberg Table
-- ============================================================================
.print 'Creating wildlife schema...'

CREATE SCHEMA IF NOT EXISTS polaris_catalog.wildlife;

.print 'OK: Schema created'
.print ''

.print 'Creating penguins Iceberg table...'

CREATE TABLE IF NOT EXISTS polaris_catalog.wildlife.penguins (
    species VARCHAR,
    island VARCHAR,
    bill_length_mm DOUBLE,
    bill_depth_mm DOUBLE,
    flipper_length_mm DOUBLE,
    body_mass_g DOUBLE,
    sex VARCHAR
);

.print 'OK: Iceberg table created via Polaris'
.print ''

-- ============================================================================
-- Step 5: Insert Data into Iceberg Table
-- ============================================================================
.print 'Inserting data into Iceberg table...'
.print '    (This writes to S3 via Polaris REST API)'

INSERT INTO polaris_catalog.wildlife.penguins
SELECT * FROM penguins_staging;

.print 'OK: Data inserted successfully'

-- Verify data was written
SELECT COUNT(*) as iceberg_record_count FROM polaris_catalog.wildlife.penguins;

-- Clean up staging table
DROP TABLE penguins_staging;

.print ''

-- ============================================================================
-- Step 6: Query and Analyze Data
-- ============================================================================
.print 'Querying penguin data...'
.print ''

.print 'Species Statistics:'
SELECT 
    species,
    COUNT(*) as count,
    ROUND(AVG(bill_length_mm), 2) as avg_bill_length_mm,
    ROUND(AVG(body_mass_g), 2) as avg_body_mass_g
FROM polaris_catalog.wildlife.penguins
GROUP BY species
ORDER BY species;

.print ''

.print 'Island Distribution:'
SELECT 
    island,
    COUNT(*) as penguin_count
FROM polaris_catalog.wildlife.penguins
GROUP BY island
ORDER BY penguin_count DESC;

.print ''

.print 'Sex Distribution by Species:'
SELECT 
    species,
    sex,
    COUNT(*) as count
FROM polaris_catalog.wildlife.penguins
GROUP BY species, sex
ORDER BY species, sex;

.print ''

-- ============================================================================
-- Step 7: Explore Iceberg Metadata
-- ============================================================================
.print 'Exploring Iceberg Metadata...'
.print ''

.print 'Table Metadata Files:'
SELECT * FROM iceberg_metadata('polaris_catalog.wildlife.penguins');

.print ''

.print 'Iceberg Snapshots:'
SELECT 
    snapshot_id,
    sequence_number,
    timestamp_ms,
    manifest_list
FROM iceberg_snapshots('polaris_catalog.wildlife.penguins');

.print ''

-- ============================================================================
-- Step 8: Advanced Queries
-- ============================================================================
.print 'Advanced Analytics:'
.print ''

.print 'Average Body Mass by Species and Island:'
SELECT 
    species,
    island,
    ROUND(AVG(body_mass_g), 2) as avg_body_mass_g,
    COUNT(*) as sample_size
FROM polaris_catalog.wildlife.penguins
GROUP BY species, island
ORDER BY species, island;

.print ''

.print 'Penguin Size Correlations:'
SELECT 
    ROUND(CORR(bill_length_mm, body_mass_g), 3) as bill_body_correlation,
    ROUND(CORR(flipper_length_mm, body_mass_g), 3) as flipper_body_correlation
FROM polaris_catalog.wildlife.penguins;

.print ''

-- ============================================================================
-- Step 9: Cleanup (Optional)
-- ============================================================================
.print 'Cleanup Section'
.print ''
.print 'To clean up the test resources, uncomment the following lines:'
.print ''
-- DROP TABLE IF EXISTS polaris_catalog.wildlife.penguins;
-- DROP SCHEMA IF EXISTS polaris_catalog.wildlife;
.print 'Cleanup commands are commented out (table preserved for exploration)'
.print ''

-- ============================================================================
-- Completion
-- ============================================================================
.print '============================================================================'
.print 'Exploration Complete!'
.print '============================================================================'
.print ''
.print 'You can now continue exploring the data using SQL queries:'
.print ''
.print '  -- List all tables'
.print '  SHOW ALL TABLES;'
.print ''
.print '  -- Query the penguins table'
.print '  SELECT * FROM polaris_catalog.wildlife.penguins LIMIT 10;'
.print ''
.print '  -- Explore metadata'
.print '  SELECT * FROM iceberg_metadata('\''polaris_catalog.wildlife.penguins'\'');'
.print '  SELECT * FROM iceberg_snapshots('\''polaris_catalog.wildlife.penguins'\'');'
.print ''
.print 'To cleanup, run:'
.print '  DROP TABLE IF EXISTS polaris_catalog.wildlife.penguins;'
.print '  DROP SCHEMA IF EXISTS polaris_catalog.wildlife;'
.print ''
.print '============================================================================'

