# Copyright 2025 Snowflake Inc.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Common utilities for Polaris Local Forge CLI.

This module contains shared constants, configuration loading, and helper functions
used across CLI commands.
"""

import os
import re
import shutil
import subprocess
import sys
from pathlib import Path

import click
import yaml
from dotenv import load_dotenv
from jinja2 import Environment, FileSystemLoader

__all__ = [
    "SKILL_DIR",
    "ANSIBLE_DIR",
    "ANSIBLE_DEFAULTS_FILE",
    "DEFAULTS",
    "STATIC_K8S_FILES",
    "TEMPLATES",
    "INIT_DIRECTORIES",
    "render_manifest",
    "get_config",
    "set_env_var",
    "run_ansible",
    "copy_static_files",
    "check_tool",
    "prompt_runtime_choice",
]

# Skill directory: where the source repo lives
SKILL_DIR = Path(__file__).parent.parent.parent.resolve()
ANSIBLE_DIR = SKILL_DIR / "polaris-forge-setup"
ANSIBLE_DEFAULTS_FILE = ANSIBLE_DIR / "defaults" / "main.yml"

# Mapping from Ansible variable names to CLI env var names
_ANSIBLE_TO_ENV = {
    "plf_cluster_name": "K3D_CLUSTER_NAME",
    "plf_k3s_version": "K3S_VERSION",
    "plf_podman_machine": "PLF_PODMAN_MACHINE",
    "plf_realm": "POLARIS_REALM",
    "plf_admin_username": "PLF_POLARIS_PRINCIPAL_NAME",
}


def _load_ansible_defaults() -> dict:
    """Load defaults from Ansible defaults/main.yml."""
    defaults = {}
    if ANSIBLE_DEFAULTS_FILE.exists():
        with open(ANSIBLE_DEFAULTS_FILE) as f:
            ansible_vars = yaml.safe_load(f) or {}
        for ansible_key, env_key in _ANSIBLE_TO_ENV.items():
            if ansible_key in ansible_vars:
                defaults[env_key] = ansible_vars[ansible_key]
    return defaults


DEFAULTS = _load_ansible_defaults()

# Static k8s files to copy when work_dir differs from SKILL_DIR
# NOTE: postgresql.yaml and polaris.yaml are GENERATED by prepare.yml, not static
STATIC_K8S_FILES = [
    "k8s/features/rustfs.yaml",
    "k8s/polaris/kustomization.yaml",
    "k8s/polaris/jobs/kustomization.yaml",
    "k8s/polaris/jobs/job-bootstrap.yaml",
    "k8s/polaris/jobs/job-purge.yaml",
]

# Template files to copy during init: (source_rel_path, dest_filename, chmod_mode or None)
TEMPLATES = [
    (".env.example", ".env", 0o600),
    ("user-project/.envrc.example", ".envrc", None),
    ("user-project/.gitignore.example", ".gitignore", None),
]

# Directories to create during init
INIT_DIRECTORIES = [".kube", "work", "bin", "k8s/features", "k8s/polaris/jobs"]


def render_manifest(
    project_name: str,
    container_runtime: str,
    podman_machine: str,
    cluster_name: str,
    manifest_status: str = "PENDING",
) -> str:
    """Render manifest from shared Jinja2 template.
    
    Uses the same template as Ansible playbooks for cross-workflow compatibility.
    Both the CLI (plf init --with-manifest) and Taskfile (task setup:all) produce
    identical manifests that can be read/updated by either workflow.
    
    Args:
        project_name: Name of the project
        container_runtime: Container runtime (docker or podman)
        podman_machine: Podman machine name (or N/A for docker)
        cluster_name: K3d cluster name
        manifest_status: Initial status (default: PENDING)
        
    Returns:
        Rendered manifest content as string
    """
    template_dir = ANSIBLE_DIR / "templates"
    env = Environment(loader=FileSystemLoader(template_dir))
    template = env.get_template("manifest.md.j2")
    return template.render(
        project_name=project_name,
        container_runtime=container_runtime,
        podman_machine=podman_machine,
        cluster_name=cluster_name,
        manifest_status=manifest_status,
    )


def get_config(work_dir: Path) -> dict:
    """Load config from .env file.
    
    Args:
        work_dir: Project working directory containing .env file
        
    Returns:
        Dictionary of configuration values merged from Ansible defaults and .env
    """
    env_file = work_dir / ".env"
    if env_file.exists():
        load_dotenv(env_file, override=True)
    # Build config from defaults, plus always include runtime-related vars
    cfg = {k: os.getenv(k, default) for k, default in DEFAULTS.items()}
    # PLF_CONTAINER_RUNTIME may not be in DEFAULTS (removed to require detection)
    # but we still need to read it from the environment
    cfg["PLF_CONTAINER_RUNTIME"] = os.getenv("PLF_CONTAINER_RUNTIME")
    cfg["PLF_PODMAN_MACHINE"] = os.getenv("PLF_PODMAN_MACHINE", "k3d")
    return cfg


def set_env_var(env_file: Path, key: str, value: str) -> bool:
    """Set or update an environment variable in .env file, preventing duplicates.

    - If key exists (uncommented), updates it in-place
    - If key doesn't exist, appends it
    - Removes any duplicate entries of the same key

    Args:
        env_file: Path to the .env file
        key: Environment variable name
        value: Value to set
        
    Returns:
        True if the file was modified
    """
    if not env_file.exists():
        env_file.write_text(f"{key}={value}\n")
        return True

    content = env_file.read_text()
    lines = content.splitlines(keepends=True)

    # Check if key exists (uncommented)
    pattern = re.compile(rf'^{re.escape(key)}=.*$', re.MULTILINE)
    matches = list(pattern.finditer(content))

    if not matches:
        # Key doesn't exist, append
        with open(env_file, "a") as f:
            if not content.endswith("\n"):
                f.write("\n")
            f.write(f"{key}={value}\n")
        return True

    # Key exists - update first occurrence, remove duplicates
    new_lines = []
    found_first = False
    for line in lines:
        stripped = line.rstrip('\n\r')
        if stripped.startswith(f"{key}="):
            if not found_first:
                new_lines.append(f"{key}={value}\n")
                found_first = True
            # Skip duplicates
        else:
            new_lines.append(line)

    new_content = "".join(new_lines)
    if new_content != content:
        env_file.write_text(new_content)
        return True
    return False


def run_ansible(playbook: str, work_dir: Path, tags: str | None = None,
                dry_run: bool = False, verbose: bool = False,
                require_aws: bool = True) -> int:
    """Run ansible playbook, return exit code.
    
    Args:
        playbook: Name of the playbook file (e.g., "prepare.yml")
        work_dir: Project working directory
        tags: Optional comma-separated Ansible tags
        dry_run: If True, only print what would be run
        verbose: If True, enable Ansible verbose output
        require_aws: If True, require project-local AWS config
        
    Returns:
        Exit code from ansible-playbook
    """
    playbook_path = ANSIBLE_DIR / playbook
    if not playbook_path.exists():
        click.echo(f"Playbook not found: {playbook_path}", err=True)
        return 1

    cmd = ["uv", "run", "ansible-playbook", str(playbook_path)]

    # CRITICAL: Override plf_output_base to write to work_dir instead of skill_dir
    # Without this, Ansible uses playbook_dir/.. which is the skill source directory
    cmd.extend(["-e", f"plf_output_base={work_dir}"])

    # CRITICAL: Use the current Python interpreter (has boto3/botocore)
    # Without this, Ansible discovers system Python which lacks dependencies
    cmd.extend(["-e", f"ansible_python_interpreter={sys.executable}"])

    if tags:
        cmd.extend(["--tags", tags])
    if verbose:
        cmd.append("-v")

    # Set ANSIBLE_CONFIG explicitly
    env = os.environ.copy()
    env["ANSIBLE_CONFIG"] = str(ANSIBLE_DIR / "ansible.cfg")

    # Isolate from user's AWS config - use project-local RustFS config instead
    # Remove profile/session env vars that could conflict with local S3
    for var in ["AWS_PROFILE", "AWS_DEFAULT_PROFILE", "AWS_SESSION_TOKEN",
                "AWS_REGION", "AWS_DEFAULT_REGION", "AWS_ACCESS_KEY_ID",
                "AWS_SECRET_ACCESS_KEY"]:
        env.pop(var, None)
    # Point to project-local .aws/ files (generated by 'prepare' command)
    # This prevents boto3 from reading ~/.aws/ (SSO tokens, profiles, etc.)
    project_aws_config = work_dir / ".aws" / "config"
    project_aws_creds = work_dir / ".aws" / "credentials"
    if require_aws:
        if not project_aws_config.exists():
            click.echo(f"Error: {project_aws_config} not found. Run 'plf prepare' first.", err=True)
            return 1
        env["AWS_CONFIG_FILE"] = str(project_aws_config)
        env["AWS_SHARED_CREDENTIALS_FILE"] = str(project_aws_creds)
    else:
        # For prepare.yml which creates .aws/ - block host config but don't require local
        env["AWS_CONFIG_FILE"] = "/dev/null"
        env["AWS_SHARED_CREDENTIALS_FILE"] = "/dev/null"

    # Set KUBECONFIG so kubernetes.core can find the cluster
    kubeconfig = work_dir / ".kube" / "config"
    if kubeconfig.exists():
        env["KUBECONFIG"] = str(kubeconfig)

    if dry_run:
        click.echo(f"Would run: {' '.join(cmd)}")
        return 0

    result = subprocess.run(cmd, cwd=work_dir, env=env)
    return result.returncode


def copy_static_files(work_dir: Path) -> None:
    """Copy static k8s files from skill dir to work dir.
    
    Only copies if work_dir is different from SKILL_DIR (i.e., running in
    a separate project directory).
    
    Args:
        work_dir: Target project working directory
    """
    if work_dir.resolve() == SKILL_DIR.resolve():
        return
    for rel_path in STATIC_K8S_FILES:
        src = SKILL_DIR / rel_path
        dst = work_dir / rel_path
        if src.exists():
            dst.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(src, dst)


def check_tool(name: str) -> bool:
    """Check if a tool is available in PATH.
    
    Args:
        name: Name of the tool/command to check
        
    Returns:
        True if the tool is found in PATH
    """
    return shutil.which(name) is not None


def prompt_runtime_choice(reason: str) -> str:
    """Prompt user to choose between Docker and Podman.
    
    Called when both are installed but neither is running.
    
    Args:
        reason: Description of why a choice is needed
        
    Returns:
        "docker" or "podman" based on user selection
    """
    click.echo(f"\n{reason}")
    click.echo("\nWhich container runtime would you like to use?")
    click.echo("  1) Docker - Start Docker Desktop manually")
    click.echo("  2) Podman - Machine will be created/started by 'doctor --fix'")
    choice = click.prompt("Enter choice", type=click.Choice(["1", "2"]), default="2")
    selected = "docker" if choice == "1" else "podman"
    click.echo(f"\nRuntime: {selected} (user selected)")
    return selected
